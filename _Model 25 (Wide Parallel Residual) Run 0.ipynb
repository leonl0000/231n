{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training directory found, 36 series\n",
      "Validation directory found, 6 series\n",
      "Testing directory found, 10 series\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import utils.tavr_torch as tavr_torch\n",
    "from utils.tavr_torch import TAVR_3_Frame, TAVR_1_Frame, TAVR_Sequence, tavr_dataloader\n",
    "from utils.visualization import display_grid, z_stretch, visualize_frame, set_figsize, get_central_slices\n",
    "from utils.loss_functions import batch_l2_loss\n",
    "from utils.run_model import train, test, save, load, get_loss_history\n",
    "from Models.basic_models import average_model, two_layer_basic, post_process\n",
    "from Models.nm_layer import nm_layer_net, Parallel_Residual\n",
    "\n",
    "set_figsize(20, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('using device:', device)\n",
    "\n",
    "# \"Pixl\", \"Slice\", or \"None\"\n",
    "preproc_type = \"pixel\"\n",
    "\n",
    "validation = TAVR_3_Frame(\"__valid\", preproc=preproc_type, preload=False)\n",
    "val_loader = tavr_dataloader(validation, batch_size=2, shuffle=True, num_workers=2)\n",
    "training = TAVR_3_Frame(\"__train\", preproc=preproc_type, preload=False)\n",
    "train_loader = tavr_dataloader(training,batch_size=2, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "ave_model = average_model()\n",
    "model = Parallel_Residual(4, [4,4],[4,1])\n",
    "post_proc = post_process(kind=preproc_type).to(device=device)\n",
    "loss_fn = batch_l2_loss()\n",
    "\n",
    "# CHANGE TO NAME OF JUPYTER NOTEBOOK\n",
    "model_name = \"Model 25 (Wide Parallel Residual) Run 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "reg = 0\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD = False\n",
    "iteration_num = -1\n",
    "\n",
    "if LOAD:\n",
    "    load(model_name, iteration_num, model, optimizer)\n",
    "    loss_history = get_loss_history(model_name)\n",
    "    model.to(device=device)\n",
    "    # I don't know why these lines are necessary\n",
    "    # or even what the hell they do\n",
    "    # but they are\n",
    "    if str(device) == 'cuda':\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                state[k] = v.cuda()\n",
    "else:\n",
    "    loss_history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If multiple GPU\n",
    "# model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0, loss = 1.4253, corrected loss = 663.2491\n",
      "Validation loss 510.3521 over 81 frames\n",
      "model saved to model_checkpoints/Model 25 (Wide Parallel Residual) Run 0/Model 25 (Wide Parallel Residual) Run 0-0\n",
      "para_0.conv_a1.weight,   \tnorm: 2.8934e+00, \tupdate norm: 1.0336e-02 \tUpdate/norm: 3.5723e-03\n",
      "para_0.conv_a1.bias,   \tnorm: 2.1399e-01, \tupdate norm: 1.9978e-03 \tUpdate/norm: 9.3357e-03\n",
      "para_0.conv_b1.weight,   \tnorm: 2.7072e+00, \tupdate norm: 1.0320e-02 \tUpdate/norm: 3.8121e-03\n",
      "para_0.conv_b1.bias,   \tnorm: 1.1737e-01, \tupdate norm: 1.9890e-03 \tUpdate/norm: 1.6946e-02\n",
      "para_0.conv_a2.weight,   \tnorm: 2.8016e+00, \tupdate norm: 2.0533e-02 \tUpdate/norm: 7.3292e-03\n",
      "para_0.conv_a2.bias,   \tnorm: 1.0215e-01, \tupdate norm: 1.9988e-03 \tUpdate/norm: 1.9568e-02\n",
      "para_0.conv_b2.weight,   \tnorm: 2.7705e+00, \tupdate norm: 2.0444e-02 \tUpdate/norm: 7.3791e-03\n",
      "para_0.conv_b2.bias,   \tnorm: 1.3266e-01, \tupdate norm: 1.9929e-03 \tUpdate/norm: 1.5022e-02\n",
      "para_0.conv_ab1.weight,   \tnorm: 2.7111e+00, \tupdate norm: 2.8549e-02 \tUpdate/norm: 1.0530e-02\n",
      "para_0.conv_ab1.bias,   \tnorm: 4.4393e-02, \tupdate norm: 1.9945e-03 \tUpdate/norm: 4.4928e-02\n",
      "para_0.conv_ab2.weight,   \tnorm: 1.5025e+00, \tupdate norm: 1.0383e-02 \tUpdate/norm: 6.9107e-03\n",
      "para_0.conv_ab2.bias,   \tnorm: 7.3529e-02, \tupdate norm: 9.9997e-04 \tUpdate/norm: 1.3600e-02\n",
      "para_1.conv_a1.weight,   \tnorm: 2.6986e+00, \tupdate norm: 1.0389e-02 \tUpdate/norm: 3.8500e-03\n",
      "para_1.conv_a1.bias,   \tnorm: 2.2118e-01, \tupdate norm: 1.9995e-03 \tUpdate/norm: 9.0402e-03\n",
      "para_1.conv_b1.weight,   \tnorm: 2.9898e+00, \tupdate norm: 1.0388e-02 \tUpdate/norm: 3.4746e-03\n",
      "para_1.conv_b1.bias,   \tnorm: 2.0294e-01, \tupdate norm: 1.9998e-03 \tUpdate/norm: 9.8543e-03\n",
      "para_1.conv_a2.weight,   \tnorm: 2.8762e+00, \tupdate norm: 2.0673e-02 \tUpdate/norm: 7.1877e-03\n",
      "para_1.conv_a2.bias,   \tnorm: 7.4379e-02, \tupdate norm: 1.9992e-03 \tUpdate/norm: 2.6879e-02\n",
      "para_1.conv_b2.weight,   \tnorm: 2.7680e+00, \tupdate norm: 2.0779e-02 \tUpdate/norm: 7.5069e-03\n",
      "para_1.conv_b2.bias,   \tnorm: 5.8374e-02, \tupdate norm: 2.0000e-03 \tUpdate/norm: 3.4261e-02\n",
      "para_1.conv_ab1.weight,   \tnorm: 2.8409e+00, \tupdate norm: 2.9316e-02 \tUpdate/norm: 1.0319e-02\n",
      "para_1.conv_ab1.bias,   \tnorm: 9.0260e-02, \tupdate norm: 1.9997e-03 \tUpdate/norm: 2.2155e-02\n",
      "para_1.conv_ab2.weight,   \tnorm: 1.2837e+00, \tupdate norm: 1.0388e-02 \tUpdate/norm: 8.0921e-03\n",
      "para_1.conv_ab2.bias,   \tnorm: 5.7435e-02, \tupdate norm: 1.0000e-03 \tUpdate/norm: 1.7411e-02\n",
      "para_2.conv_a1.weight,   \tnorm: 2.9474e+00, \tupdate norm: 1.0384e-02 \tUpdate/norm: 3.5232e-03\n",
      "para_2.conv_a1.bias,   \tnorm: 2.0900e-01, \tupdate norm: 1.9996e-03 \tUpdate/norm: 9.5673e-03\n",
      "para_2.conv_b1.weight,   \tnorm: 2.6396e+00, \tupdate norm: 1.0320e-02 \tUpdate/norm: 3.9098e-03\n",
      "para_2.conv_b1.bias,   \tnorm: 2.1843e-01, \tupdate norm: 1.9938e-03 \tUpdate/norm: 9.1280e-03\n",
      "para_2.conv_a2.weight,   \tnorm: 2.7008e+00, \tupdate norm: 2.0748e-02 \tUpdate/norm: 7.6822e-03\n",
      "para_2.conv_a2.bias,   \tnorm: 1.0823e-01, \tupdate norm: 1.9998e-03 \tUpdate/norm: 1.8477e-02\n",
      "para_2.conv_b2.weight,   \tnorm: 2.8601e+00, \tupdate norm: 2.0491e-02 \tUpdate/norm: 7.1644e-03\n",
      "para_2.conv_b2.bias,   \tnorm: 7.8816e-02, \tupdate norm: 1.9996e-03 \tUpdate/norm: 2.5370e-02\n",
      "para_2.conv_ab1.weight,   \tnorm: 2.8937e+00, \tupdate norm: 2.9082e-02 \tUpdate/norm: 1.0050e-02\n",
      "para_2.conv_ab1.bias,   \tnorm: 7.5120e-02, \tupdate norm: 1.9987e-03 \tUpdate/norm: 2.6607e-02\n",
      "para_2.conv_ab2.weight,   \tnorm: 1.2415e+00, \tupdate norm: 1.0381e-02 \tUpdate/norm: 8.3616e-03\n",
      "para_2.conv_ab2.bias,   \tnorm: 1.0447e-02, \tupdate norm: 9.9999e-04 \tUpdate/norm: 9.5723e-02\n",
      "para_3.conv_a1.weight,   \tnorm: 2.6787e+00, \tupdate norm: 1.0391e-02 \tUpdate/norm: 3.8793e-03\n",
      "para_3.conv_a1.bias,   \tnorm: 2.2028e-01, \tupdate norm: 2.0000e-03 \tUpdate/norm: 9.0793e-03\n",
      "para_3.conv_b1.weight,   \tnorm: 3.0466e+00, \tupdate norm: 1.0392e-02 \tUpdate/norm: 3.4111e-03\n",
      "para_3.conv_b1.bias,   \tnorm: 1.9184e-01, \tupdate norm: 2.0000e-03 \tUpdate/norm: 1.0425e-02\n",
      "para_3.conv_a2.weight,   \tnorm: 2.9103e+00, \tupdate norm: 2.0784e-02 \tUpdate/norm: 7.1415e-03\n",
      "para_3.conv_a2.bias,   \tnorm: 1.2959e-01, \tupdate norm: 1.9999e-03 \tUpdate/norm: 1.5433e-02\n",
      "para_3.conv_b2.weight,   \tnorm: 2.6495e+00, \tupdate norm: 2.0782e-02 \tUpdate/norm: 7.8439e-03\n",
      "para_3.conv_b2.bias,   \tnorm: 6.8727e-02, \tupdate norm: 2.0000e-03 \tUpdate/norm: 2.9100e-02\n",
      "para_3.conv_ab1.weight,   \tnorm: 2.9288e+00, \tupdate norm: 2.9351e-02 \tUpdate/norm: 1.0022e-02\n",
      "para_3.conv_ab1.bias,   \tnorm: 4.8164e-02, \tupdate norm: 2.0000e-03 \tUpdate/norm: 4.1524e-02\n",
      "para_3.conv_ab2.weight,   \tnorm: 1.2628e+00, \tupdate norm: 1.0392e-02 \tUpdate/norm: 8.2295e-03\n",
      "para_3.conv_ab2.bias,   \tnorm: 2.3015e-02, \tupdate norm: 1.0000e-03 \tUpdate/norm: 4.3451e-02\n",
      "\n",
      "... 0.5306... 0.1887... 0.0711\n",
      "Iter 10... 0.0785... 0.0544... 0.0842\n",
      "Iter 20... 0.0701... 0.0645... 0.0700\n",
      "Iter 30... 0.0580... 0.0462... 0.0650\n",
      "Iter 40... 0.0811... 0.0633... 0.0597\n",
      "Iter 50... 0.1072... 0.0807... 0.0659\n",
      "Iteration 60, loss = 0.1035, corrected loss = 48.1536\n",
      "Validation loss 37.6900 over 81 frames\n",
      "model saved to model_checkpoints/Model 25 (Wide Parallel Residual) Run 0/Model 25 (Wide Parallel Residual) Run 0-60\n",
      "para_0.conv_a1.weight,   \tnorm: 2.8853e+00, \tupdate norm: 7.4935e-05 \tUpdate/norm: 2.5971e-05\n",
      "para_0.conv_a1.bias,   \tnorm: 2.3571e-01, \tupdate norm: 7.9059e-06 \tUpdate/norm: 3.3540e-05\n",
      "para_0.conv_b1.weight,   \tnorm: 2.6967e+00, \tupdate norm: 9.5175e-05 \tUpdate/norm: 3.5293e-05\n",
      "para_0.conv_b1.bias,   \tnorm: 1.2892e-01, \tupdate norm: 3.6387e-05 \tUpdate/norm: 2.8224e-04\n",
      "para_0.conv_a2.weight,   \tnorm: 2.8000e+00, \tupdate norm: 1.6173e-04 \tUpdate/norm: 5.7761e-05\n",
      "para_0.conv_a2.bias,   \tnorm: 1.0622e-01, \tupdate norm: 8.5844e-06 \tUpdate/norm: 8.0815e-05\n",
      "para_0.conv_b2.weight,   \tnorm: 2.7912e+00, \tupdate norm: 3.3755e-04 \tUpdate/norm: 1.2093e-04\n",
      "para_0.conv_b2.bias,   \tnorm: 1.2647e-01, \tupdate norm: 3.0849e-05 \tUpdate/norm: 2.4394e-04\n",
      "para_0.conv_ab1.weight,   \tnorm: 2.7121e+00, \tupdate norm: 3.5046e-04 \tUpdate/norm: 1.2922e-04\n",
      "para_0.conv_ab1.bias,   \tnorm: 5.4908e-02, \tupdate norm: 1.1740e-05 \tUpdate/norm: 2.1382e-04\n",
      "para_0.conv_ab2.weight,   \tnorm: 1.5217e+00, \tupdate norm: 6.0868e-05 \tUpdate/norm: 3.9999e-05\n",
      "para_0.conv_ab2.bias,   \tnorm: 6.1124e-02, \tupdate norm: 5.7295e-06 \tUpdate/norm: 9.3736e-05\n",
      "para_1.conv_a1.weight,   \tnorm: 2.6834e+00, \tupdate norm: 3.2191e-05 \tUpdate/norm: 1.1997e-05\n",
      "para_1.conv_a1.bias,   \tnorm: 2.2473e-01, \tupdate norm: 6.2096e-06 \tUpdate/norm: 2.7632e-05\n",
      "para_1.conv_b1.weight,   \tnorm: 3.0008e+00, \tupdate norm: 3.9335e-05 \tUpdate/norm: 1.3108e-05\n",
      "para_1.conv_b1.bias,   \tnorm: 2.1473e-01, \tupdate norm: 8.4600e-06 \tUpdate/norm: 3.9399e-05\n",
      "para_1.conv_a2.weight,   \tnorm: 2.8650e+00, \tupdate norm: 9.3933e-05 \tUpdate/norm: 3.2786e-05\n",
      "para_1.conv_a2.bias,   \tnorm: 9.3197e-02, \tupdate norm: 1.0263e-05 \tUpdate/norm: 1.1012e-04\n",
      "para_1.conv_b2.weight,   \tnorm: 2.7717e+00, \tupdate norm: 7.0062e-05 \tUpdate/norm: 2.5277e-05\n",
      "para_1.conv_b2.bias,   \tnorm: 5.2887e-02, \tupdate norm: 6.7257e-06 \tUpdate/norm: 1.2717e-04\n",
      "para_1.conv_ab1.weight,   \tnorm: 2.8708e+00, \tupdate norm: 1.1530e-04 \tUpdate/norm: 4.0164e-05\n",
      "para_1.conv_ab1.bias,   \tnorm: 1.0468e-01, \tupdate norm: 7.0299e-06 \tUpdate/norm: 6.7160e-05\n",
      "para_1.conv_ab2.weight,   \tnorm: 1.2937e+00, \tupdate norm: 4.2888e-05 \tUpdate/norm: 3.3152e-05\n",
      "para_1.conv_ab2.bias,   \tnorm: 4.5833e-02, \tupdate norm: 3.4049e-06 \tUpdate/norm: 7.4290e-05\n",
      "para_2.conv_a1.weight,   \tnorm: 2.9429e+00, \tupdate norm: 3.4395e-05 \tUpdate/norm: 1.1687e-05\n",
      "para_2.conv_a1.bias,   \tnorm: 1.9936e-01, \tupdate norm: 6.4365e-06 \tUpdate/norm: 3.2285e-05\n",
      "para_2.conv_b1.weight,   \tnorm: 2.6434e+00, \tupdate norm: 4.5804e-05 \tUpdate/norm: 1.7328e-05\n",
      "para_2.conv_b1.bias,   \tnorm: 2.2181e-01, \tupdate norm: 9.6619e-06 \tUpdate/norm: 4.3560e-05\n",
      "para_2.conv_a2.weight,   \tnorm: 2.7182e+00, \tupdate norm: 8.7297e-05 \tUpdate/norm: 3.2115e-05\n",
      "para_2.conv_a2.bias,   \tnorm: 1.0705e-01, \tupdate norm: 7.6829e-06 \tUpdate/norm: 7.1768e-05\n",
      "para_2.conv_b2.weight,   \tnorm: 2.8478e+00, \tupdate norm: 1.2338e-04 \tUpdate/norm: 4.3326e-05\n",
      "para_2.conv_b2.bias,   \tnorm: 9.5242e-02, \tupdate norm: 1.0554e-05 \tUpdate/norm: 1.1081e-04\n",
      "para_2.conv_ab1.weight,   \tnorm: 2.9099e+00, \tupdate norm: 4.4424e-04 \tUpdate/norm: 1.5266e-04\n",
      "para_2.conv_ab1.bias,   \tnorm: 7.3285e-02, \tupdate norm: 3.0908e-05 \tUpdate/norm: 4.2176e-04\n",
      "para_2.conv_ab2.weight,   \tnorm: 1.2606e+00, \tupdate norm: 1.1800e-04 \tUpdate/norm: 9.3606e-05\n",
      "para_2.conv_ab2.bias,   \tnorm: 1.2367e-03, \tupdate norm: 4.0350e-06 \tUpdate/norm: 3.2627e-03\n",
      "para_3.conv_a1.weight,   \tnorm: 2.6466e+00, \tupdate norm: 7.7671e-05 \tUpdate/norm: 2.9347e-05\n",
      "para_3.conv_a1.bias,   \tnorm: 2.4043e-01, \tupdate norm: 2.0332e-05 \tUpdate/norm: 8.4566e-05\n",
      "para_3.conv_b1.weight,   \tnorm: 3.0485e+00, \tupdate norm: 4.2450e-05 \tUpdate/norm: 1.3925e-05\n",
      "para_3.conv_b1.bias,   \tnorm: 1.9111e-01, \tupdate norm: 6.3646e-06 \tUpdate/norm: 3.3303e-05\n",
      "para_3.conv_a2.weight,   \tnorm: 2.8938e+00, \tupdate norm: 1.1828e-04 \tUpdate/norm: 4.0873e-05\n",
      "para_3.conv_a2.bias,   \tnorm: 1.3120e-01, \tupdate norm: 1.5238e-05 \tUpdate/norm: 1.1615e-04\n",
      "para_3.conv_b2.weight,   \tnorm: 2.6355e+00, \tupdate norm: 1.7265e-04 \tUpdate/norm: 6.5508e-05\n",
      "para_3.conv_b2.bias,   \tnorm: 5.1647e-02, \tupdate norm: 1.9301e-05 \tUpdate/norm: 3.7371e-04\n",
      "para_3.conv_ab1.weight,   \tnorm: 2.9655e+00, \tupdate norm: 3.2547e-04 \tUpdate/norm: 1.0975e-04\n",
      "para_3.conv_ab1.bias,   \tnorm: 5.8054e-02, \tupdate norm: 2.1700e-05 \tUpdate/norm: 3.7379e-04\n",
      "para_3.conv_ab2.weight,   \tnorm: 1.2587e+00, \tupdate norm: 9.5073e-05 \tUpdate/norm: 7.5531e-05\n",
      "para_3.conv_ab2.bias,   \tnorm: 5.8259e-03, \tupdate norm: 7.3561e-06 \tUpdate/norm: 1.2627e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... 0.0499... 0.0847... 0.0622\n",
      "Iter 70... 0.0607... 0.0601... 0.0656\n",
      "Iter 80... 0.0851... 0.0846... 0.1035\n",
      "Iter 90... 0.0778... 0.1040... 0.0559\n",
      "Iter 100... 0.0519... 0.0715... 0.0837\n",
      "Iter 110... 0.0993... 0.0929... 0.0558\n",
      "Iteration 120, loss = 0.0893, corrected loss = 41.5502\n",
      "Validation loss 37.7454 over 81 frames\n",
      "model saved to model_checkpoints/Model 25 (Wide Parallel Residual) Run 0/Model 25 (Wide Parallel Residual) Run 0-120\n",
      "para_0.conv_a1.weight,   \tnorm: 2.8845e+00, \tupdate norm: 4.4377e-05 \tUpdate/norm: 1.5385e-05\n",
      "para_0.conv_a1.bias,   \tnorm: 2.3582e-01, \tupdate norm: 9.9711e-07 \tUpdate/norm: 4.2282e-06\n",
      "para_0.conv_b1.weight,   \tnorm: 2.6967e+00, \tupdate norm: 7.9512e-05 \tUpdate/norm: 2.9485e-05\n",
      "para_0.conv_b1.bias,   \tnorm: 1.3094e-01, \tupdate norm: 3.0227e-05 \tUpdate/norm: 2.3084e-04\n",
      "para_0.conv_a2.weight,   \tnorm: 2.7994e+00, \tupdate norm: 1.2453e-04 \tUpdate/norm: 4.4485e-05\n",
      "para_0.conv_a2.bias,   \tnorm: 1.0629e-01, \tupdate norm: 2.8480e-06 \tUpdate/norm: 2.6794e-05\n",
      "para_0.conv_b2.weight,   \tnorm: 2.7929e+00, \tupdate norm: 2.7186e-04 \tUpdate/norm: 9.7341e-05\n",
      "para_0.conv_b2.bias,   \tnorm: 1.2572e-01, \tupdate norm: 1.8792e-05 \tUpdate/norm: 1.4948e-04\n",
      "para_0.conv_ab1.weight,   \tnorm: 2.7118e+00, \tupdate norm: 3.1919e-04 \tUpdate/norm: 1.1771e-04\n",
      "para_0.conv_ab1.bias,   \tnorm: 5.4939e-02, \tupdate norm: 3.3945e-06 \tUpdate/norm: 6.1787e-05\n",
      "para_0.conv_ab2.weight,   \tnorm: 1.5219e+00, \tupdate norm: 2.4120e-05 \tUpdate/norm: 1.5848e-05\n",
      "para_0.conv_ab2.bias,   \tnorm: 6.0975e-02, \tupdate norm: 1.4976e-06 \tUpdate/norm: 2.4560e-05\n",
      "para_1.conv_a1.weight,   \tnorm: 2.6833e+00, \tupdate norm: 3.2190e-06 \tUpdate/norm: 1.1997e-06\n",
      "para_1.conv_a1.bias,   \tnorm: 2.2475e-01, \tupdate norm: 3.1829e-08 \tUpdate/norm: 1.4162e-07\n",
      "para_1.conv_b1.weight,   \tnorm: 3.0008e+00, \tupdate norm: 4.3794e-06 \tUpdate/norm: 1.4594e-06\n",
      "para_1.conv_b1.bias,   \tnorm: 2.1476e-01, \tupdate norm: 1.6006e-07 \tUpdate/norm: 7.4527e-07\n",
      "para_1.conv_a2.weight,   \tnorm: 2.8650e+00, \tupdate norm: 2.9810e-05 \tUpdate/norm: 1.0405e-05\n",
      "para_1.conv_a2.bias,   \tnorm: 9.3328e-02, \tupdate norm: 5.4570e-07 \tUpdate/norm: 5.8472e-06\n",
      "para_1.conv_b2.weight,   \tnorm: 2.7717e+00, \tupdate norm: 7.0778e-06 \tUpdate/norm: 2.5536e-06\n",
      "para_1.conv_b2.bias,   \tnorm: 5.2891e-02, \tupdate norm: 1.1612e-07 \tUpdate/norm: 2.1955e-06\n",
      "para_1.conv_ab1.weight,   \tnorm: 2.8710e+00, \tupdate norm: 1.4155e-05 \tUpdate/norm: 4.9303e-06\n",
      "para_1.conv_ab1.bias,   \tnorm: 1.0473e-01, \tupdate norm: 1.6892e-07 \tUpdate/norm: 1.6130e-06\n",
      "para_1.conv_ab2.weight,   \tnorm: 1.2937e+00, \tupdate norm: 8.7667e-06 \tUpdate/norm: 6.7764e-06\n",
      "para_1.conv_ab2.bias,   \tnorm: 4.5795e-02, \tupdate norm: 4.4703e-08 \tUpdate/norm: 9.7617e-07\n",
      "para_2.conv_a1.weight,   \tnorm: 2.9429e+00, \tupdate norm: 1.9926e-06 \tUpdate/norm: 6.7708e-07\n",
      "para_2.conv_a1.bias,   \tnorm: 1.9934e-01, \tupdate norm: 4.8120e-07 \tUpdate/norm: 2.4139e-06\n",
      "para_2.conv_b1.weight,   \tnorm: 2.6434e+00, \tupdate norm: 1.0008e-05 \tUpdate/norm: 3.7858e-06\n",
      "para_2.conv_b1.bias,   \tnorm: 2.2228e-01, \tupdate norm: 4.3420e-06 \tUpdate/norm: 1.9534e-05\n",
      "para_2.conv_a2.weight,   \tnorm: 2.7181e+00, \tupdate norm: 1.7130e-05 \tUpdate/norm: 6.3023e-06\n",
      "para_2.conv_a2.bias,   \tnorm: 1.0704e-01, \tupdate norm: 1.7847e-07 \tUpdate/norm: 1.6672e-06\n",
      "para_2.conv_b2.weight,   \tnorm: 2.8477e+00, \tupdate norm: 3.3967e-05 \tUpdate/norm: 1.1928e-05\n",
      "para_2.conv_b2.bias,   \tnorm: 9.5391e-02, \tupdate norm: 1.6313e-06 \tUpdate/norm: 1.7101e-05\n",
      "para_2.conv_ab1.weight,   \tnorm: 2.9102e+00, \tupdate norm: 2.5428e-04 \tUpdate/norm: 8.7374e-05\n",
      "para_2.conv_ab1.bias,   \tnorm: 7.3329e-02, \tupdate norm: 1.2354e-05 \tUpdate/norm: 1.6847e-04\n",
      "para_2.conv_ab2.weight,   \tnorm: 1.2614e+00, \tupdate norm: 4.5890e-05 \tUpdate/norm: 3.6381e-05\n",
      "para_2.conv_ab2.bias,   \tnorm: 1.2938e-03, \tupdate norm: 1.8522e-07 \tUpdate/norm: 1.4316e-04\n",
      "para_3.conv_a1.weight,   \tnorm: 2.6463e+00, \tupdate norm: 2.9590e-05 \tUpdate/norm: 1.1182e-05\n",
      "para_3.conv_a1.bias,   \tnorm: 2.4053e-01, \tupdate norm: 1.5594e-05 \tUpdate/norm: 6.4833e-05\n",
      "para_3.conv_b1.weight,   \tnorm: 3.0486e+00, \tupdate norm: 8.8488e-06 \tUpdate/norm: 2.9026e-06\n",
      "para_3.conv_b1.bias,   \tnorm: 1.9103e-01, \tupdate norm: 2.5663e-06 \tUpdate/norm: 1.3434e-05\n",
      "para_3.conv_a2.weight,   \tnorm: 2.8934e+00, \tupdate norm: 5.6962e-05 \tUpdate/norm: 1.9687e-05\n",
      "para_3.conv_a2.bias,   \tnorm: 1.3105e-01, \tupdate norm: 4.9270e-06 \tUpdate/norm: 3.7597e-05\n",
      "para_3.conv_b2.weight,   \tnorm: 2.6355e+00, \tupdate norm: 1.2021e-04 \tUpdate/norm: 4.5610e-05\n",
      "para_3.conv_b2.bias,   \tnorm: 5.1253e-02, \tupdate norm: 1.1542e-05 \tUpdate/norm: 2.2519e-04\n",
      "para_3.conv_ab1.weight,   \tnorm: 2.9666e+00, \tupdate norm: 1.9256e-04 \tUpdate/norm: 6.4909e-05\n",
      "para_3.conv_ab1.bias,   \tnorm: 5.8332e-02, \tupdate norm: 9.4134e-06 \tUpdate/norm: 1.6138e-04\n",
      "para_3.conv_ab2.weight,   \tnorm: 1.2588e+00, \tupdate norm: 3.1983e-05 \tUpdate/norm: 2.5408e-05\n",
      "para_3.conv_ab2.bias,   \tnorm: 5.6946e-03, \tupdate norm: 1.2144e-06 \tUpdate/norm: 2.1326e-04\n",
      "\n",
      "... 0.0702... 0.0552... 0.0845\n",
      "Iter 130.... 0.0729\n",
      "Iter 140... 0.0540... 0.0600... 0.0605\n",
      "Iter 150... 0.0993... 0.0818... 0.1007\n",
      "Iter 160... 0.1109... 0.0508... 0.0944\n",
      "Iter 170... 0.0863"
     ]
    }
   ],
   "source": [
    "train(model, post_proc, optimizer, train_loader, val_loader, loss_fn, device, \n",
    "         model_name, loss_history,\n",
    "          epochs=2, print_every=60, print_level=4, lr_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One last test + visualize results on 1 validation sequence\n",
    "\n",
    "test(model, post_proc, val_loader, loss_fn, device)\n",
    "test(ave_model, post_proc, val_loader, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for t, (x1, y, x2, mask, max_z) in enumerate(val_loader):\n",
    "        x1 = x1.to(device=device)  # move to device, e.g. GPU\n",
    "        y = post_proc(y.to(device=device))\n",
    "        x2 = x2.to(device=device)\n",
    "        mask = mask.to(device=device)\n",
    "        max_z = max_z.to(device=device)\n",
    "        \n",
    "        y_hat = post_proc(model((x1, x2)))\n",
    "        L2_to_ground = loss_fn((y, y_hat, mask, max_z))\n",
    "        L2_to_ave = loss_fn((post_proc(ave_model((x1,x2))), y_hat, mask, max_z))\n",
    "        print(\"Batch %d. Prediction-Real dist: %.5f, Prediction-Ave dist:%.5f\"%(t, L2_to_ground.item(), L2_to_ave.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seq = TAVR_Sequence(\"__valid\", preproc=preproc_type)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    ave_frames = [post_proc(val_seq[0][0].to(device=device))]\n",
    "    for i in range(2,9,2):\n",
    "        ave_frame = model((val_seq[0][i-2][None,:].to(device=device), val_seq[0][i][None,:].to(device=device)))\n",
    "        ave_frames += [post_proc(ave_frame[0][0]),  post_proc(val_seq[0][i].to(device=device))]\n",
    "    ave_frames += [post_proc(val_seq[0][9].to(device=device))]\n",
    "    ave_frames_slices = []\n",
    "    for f in ave_frames:\n",
    "        ave_frames_slices += get_central_slices(f)\n",
    "    set_figsize(6,20)\n",
    "    display_grid(10, 3, ave_frames_slices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
