{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import utils.tavr_torch as tavr_torch\n",
    "from utils.tavr_torch import TAVR_3_Frame, TAVR_1_Frame, TAVR_Sequence, tavr_dataloader\n",
    "from utils.visualization import display_grid, z_stretch, visualize_frame, set_figsize, get_central_slices\n",
    "from utils.loss_functions import batch_l2_loss, batch_mse_loss\n",
    "from utils.run_model import train, test\n",
    "from Models.basic_models import average_model, two_layer_basic\n",
    "\n",
    "\n",
    "set_figsize(20, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('using device:', device)\n",
    "\n",
    "validation = TAVR_3_Frame(\"__valid\")\n",
    "val_loader = tavr_dataloader(validation, batch_size=8, shuffle=True, num_workers=2)\n",
    "training = TAVR_3_Frame(\"__train\")\n",
    "train_loader = tavr_dataloader(training, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "ave_model = average_model()\n",
    "model = two_layer_basic()\n",
    "loss_fn = batch_mse_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.025e+05, max_z_sum 287 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 925564.0\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.591e+05, max_z_sum 289 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1176161.875\n",
      "torch.Size([4, 1, 77, 256, 256]) torch.Size([4, 77, 256, 256])\n",
      "\tmean 2.344e+05, max_z_sum 268 torch.Size([4, 4, 77, 256, 256])\n",
      "BS & loss 4 1077383.75\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.253e+05, max_z_sum 295 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1001882.4375\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.472e+05, max_z_sum 310 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 623028.6875\n",
      "torch.Size([4, 1, 73, 256, 256]) torch.Size([4, 73, 256, 256])\n",
      "\tmean 2.599e+05, max_z_sum 236 torch.Size([4, 4, 73, 256, 256])\n",
      "BS & loss 4 1286085.5\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.492e+05, max_z_sum 252 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1297578.5\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.606e+05, max_z_sum 293 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1167016.875\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.188e+05, max_z_sum 273 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1051727.5\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.789e+05, max_z_sum 305 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 769399.1875\n",
      "torch.Size([4, 1, 77, 256, 256]) torch.Size([4, 77, 256, 256])\n",
      "\tmean 2.108e+05, max_z_sum 233 torch.Size([4, 4, 77, 256, 256])\n",
      "BS & loss 4 1114562.375\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.846e+05, max_z_sum 266 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1403677.125\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.778e+05, max_z_sum 275 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1325561.75\n",
      "torch.Size([4, 1, 73, 256, 256]) torch.Size([4, 73, 256, 256])\n",
      "\tmean 2.415e+05, max_z_sum 243 torch.Size([4, 4, 73, 256, 256])\n",
      "BS & loss 4 1160797.0\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.993e+05, max_z_sum 270 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1454381.125\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.512e+05, max_z_sum 280 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1176921.875\n",
      "torch.Size([4, 1, 77, 256, 256]) torch.Size([4, 77, 256, 256])\n",
      "\tmean 2.341e+05, max_z_sum 268 torch.Size([4, 4, 77, 256, 256])\n",
      "BS & loss 4 1076076.875\n",
      "torch.Size([4, 1, 59, 256, 256]) torch.Size([4, 59, 256, 256])\n",
      "\tmean 1.823e+05, max_z_sum 215 torch.Size([4, 4, 59, 256, 256])\n",
      "BS & loss 4 800514.25\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.233e+05, max_z_sum 301 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 537511.875\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.685e+05, max_z_sum 245 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1437668.0\n",
      "torch.Size([1, 1, 52, 256, 256]) torch.Size([1, 52, 256, 256])\n",
      "\tmean 3.742e+04, max_z_sum 52 torch.Size([1, 1, 52, 256, 256])\n",
      "BS & loss 4 37419.20703125\n",
      "Validation loss 1041564.5000 over 81 frames\n",
      "\n",
      "\n",
      "torch.Size([4, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.380e+03, max_z_sum 300 torch.Size([4, 82, 256, 256])\n",
      "BS & loss 4 1508.505859375\n",
      "torch.Size([4, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.111e+03, max_z_sum 289 torch.Size([4, 82, 256, 256])\n",
      "BS & loss 4 1260.468017578125\n",
      "torch.Size([4, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.109e+03, max_z_sum 305 torch.Size([4, 82, 256, 256])\n",
      "BS & loss 4 1192.7733154296875\n",
      "torch.Size([4, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.037e+03, max_z_sum 280 torch.Size([4, 82, 256, 256])\n",
      "BS & loss 4 1215.2843017578125\n",
      "torch.Size([4, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.244e+03, max_z_sum 245 torch.Size([4, 82, 256, 256])\n",
      "BS & loss 4 1664.96533203125\n",
      "torch.Size([4, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.333e+03, max_z_sum 266 torch.Size([4, 82, 256, 256])\n",
      "BS & loss 4 1643.6285400390625\n",
      "torch.Size([4, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 8.984e+02, max_z_sum 245 torch.Size([4, 82, 256, 256])\n",
      "BS & loss 4 1202.815673828125\n",
      "torch.Size([4, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.078e+03, max_z_sum 266 torch.Size([4, 82, 256, 256])\n",
      "BS & loss 4 1329.749755859375\n",
      "torch.Size([4, 77, 256, 256]) torch.Size([4, 77, 256, 256])\n",
      "\tmean 1.521e+03, max_z_sum 261 torch.Size([4, 77, 256, 256])\n",
      "BS & loss 4 1795.1751708984375\n",
      "torch.Size([4, 77, 256, 256]) torch.Size([4, 77, 256, 256])\n",
      "\tmean 1.190e+03, max_z_sum 282 torch.Size([4, 77, 256, 256])\n",
      "BS & loss 4 1299.981689453125\n",
      "torch.Size([4, 77, 256, 256]) torch.Size([4, 77, 256, 256])\n",
      "\tmean 1.472e+03, max_z_sum 247 torch.Size([4, 77, 256, 256])\n",
      "BS & loss 4 1835.1864013671875\n",
      "torch.Size([4, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.087e+03, max_z_sum 305 torch.Size([4, 82, 256, 256])\n",
      "BS & loss 4 1169.093017578125\n",
      "torch.Size([4, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.414e+03, max_z_sum 284 torch.Size([4, 82, 256, 256])\n",
      "BS & loss 4 1633.180908203125\n",
      "torch.Size([4, 52, 256, 256]) torch.Size([4, 52, 256, 256])\n",
      "\tmean 2.122e+03, max_z_sum 208 torch.Size([4, 52, 256, 256])\n",
      "BS & loss 4 2122.1474609375\n",
      "torch.Size([4, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.215e+03, max_z_sum 280 torch.Size([4, 82, 256, 256])\n",
      "BS & loss 4 1423.091796875\n",
      "torch.Size([4, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.085e+03, max_z_sum 273 torch.Size([4, 82, 256, 256])\n",
      "BS & loss 4 1303.0419921875\n",
      "torch.Size([4, 77, 256, 256]) torch.Size([4, 77, 256, 256])\n",
      "\tmean 1.354e+03, max_z_sum 282 torch.Size([4, 77, 256, 256])\n",
      "BS & loss 4 1478.849365234375\n",
      "torch.Size([4, 73, 256, 256]) torch.Size([4, 73, 256, 256])\n",
      "\tmean 1.037e+03, max_z_sum 250 torch.Size([4, 73, 256, 256])\n",
      "BS & loss 4 1210.9930419921875\n",
      "torch.Size([4, 77, 256, 256]) torch.Size([4, 77, 256, 256])\n",
      "\tmean 1.551e+03, max_z_sum 261 torch.Size([4, 77, 256, 256])\n",
      "BS & loss 4 1829.777099609375\n",
      "torch.Size([4, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.089e+03, max_z_sum 245 torch.Size([4, 82, 256, 256])\n",
      "BS & loss 4 1458.5205078125\n",
      "torch.Size([1, 82, 256, 256]) torch.Size([1, 82, 256, 256])\n",
      "\tmean 1.326e+03, max_z_sum 82 torch.Size([1, 82, 256, 256])\n",
      "BS & loss 4 1325.90380859375\n",
      "Validation loss 1424.2240 over 81 frames\n",
      "\n",
      "\n",
      "torch.Size([16, 1, 82, 256, 256]) torch.Size([16, 82, 256, 256])\n",
      "\tmean 2.623e+05, max_z_sum 1024 torch.Size([16, 16, 82, 256, 256])\n",
      "BS & loss 16 5377123.5\n",
      "torch.Size([16, 1, 82, 256, 256]) torch.Size([16, 82, 256, 256])\n",
      "\tmean 2.743e+05, max_z_sum 1137 torch.Size([16, 16, 82, 256, 256])\n",
      "BS & loss 16 5064051.5\n",
      "torch.Size([16, 1, 82, 256, 256]) torch.Size([16, 82, 256, 256])\n",
      "\tmean 2.786e+05, max_z_sum 1100 torch.Size([16, 16, 82, 256, 256])\n",
      "BS & loss 16 5317007.0\n",
      "torch.Size([16, 1, 82, 256, 256]) torch.Size([16, 82, 256, 256])\n",
      "\tmean 2.904e+05, max_z_sum 1043 torch.Size([16, 16, 82, 256, 256])\n",
      "BS & loss 16 5844199.0\n",
      "torch.Size([16, 1, 82, 256, 256]) torch.Size([16, 82, 256, 256])\n",
      "\tmean 2.946e+05, max_z_sum 1100 torch.Size([16, 16, 82, 256, 256])\n",
      "BS & loss 16 5622141.0\n",
      "torch.Size([1, 1, 52, 256, 256]) torch.Size([1, 52, 256, 256])\n",
      "\tmean 3.570e+04, max_z_sum 52 torch.Size([1, 1, 52, 256, 256])\n",
      "BS & loss 16 35700.96484375\n",
      "Validation loss 4537792.0000 over 81 frames\n",
      "\n",
      "\n",
      "torch.Size([16, 82, 256, 256]) torch.Size([16, 82, 256, 256])\n",
      "\tmean 1.294e+03, max_z_sum 1088 torch.Size([16, 82, 256, 256])\n",
      "BS & loss 16 1560.6243896484375\n",
      "torch.Size([16, 82, 256, 256]) torch.Size([16, 82, 256, 256])\n",
      "\tmean 1.206e+03, max_z_sum 1137 torch.Size([16, 82, 256, 256])\n",
      "BS & loss 16 1392.008056640625\n",
      "torch.Size([16, 82, 256, 256]) torch.Size([16, 82, 256, 256])\n",
      "\tmean 1.240e+03, max_z_sum 1008 torch.Size([16, 82, 256, 256])\n",
      "BS & loss 16 1614.3321533203125\n",
      "torch.Size([16, 82, 256, 256]) torch.Size([16, 82, 256, 256])\n",
      "\tmean 1.164e+03, max_z_sum 1093 torch.Size([16, 82, 256, 256])\n",
      "BS & loss 16 1396.9368896484375\n",
      "torch.Size([16, 82, 256, 256]) torch.Size([16, 82, 256, 256])\n",
      "\tmean 1.108e+03, max_z_sum 1078 torch.Size([16, 82, 256, 256])\n",
      "BS & loss 16 1348.7562255859375\n",
      "torch.Size([1, 52, 256, 256]) torch.Size([1, 52, 256, 256])\n",
      "\tmean 1.799e+03, max_z_sum 52 torch.Size([1, 52, 256, 256])\n",
      "BS & loss 16 1798.85302734375\n",
      "Validation loss 1237.5143 over 81 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.835e+05, max_z_sum 266 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1398198.625\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.512e+05, max_z_sum 280 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1177267.375\n",
      "torch.Size([4, 1, 73, 256, 256]) torch.Size([4, 73, 256, 256])\n",
      "\tmean 1.498e+05, max_z_sum 278 torch.Size([4, 4, 73, 256, 256])\n",
      "BS & loss 4 629293.625\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.423e+05, max_z_sum 277 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1147785.0\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.522e+05, max_z_sum 252 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1313137.625\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.499e+05, max_z_sum 280 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1171121.75\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.408e+05, max_z_sum 318 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 581061.9375\n",
      "torch.Size([4, 1, 77, 256, 256]) torch.Size([4, 77, 256, 256])\n",
      "\tmean 2.570e+05, max_z_sum 247 torch.Size([4, 4, 77, 256, 256])\n",
      "BS & loss 4 1281997.0\n",
      "torch.Size([4, 1, 73, 256, 256]) torch.Size([4, 73, 256, 256])\n",
      "\tmean 2.585e+05, max_z_sum 257 torch.Size([4, 4, 73, 256, 256])\n",
      "BS & loss 4 1174759.125\n",
      "torch.Size([4, 1, 73, 256, 256]) torch.Size([4, 73, 256, 256])\n",
      "\tmean 2.562e+05, max_z_sum 236 torch.Size([4, 4, 73, 256, 256])\n",
      "BS & loss 4 1268169.75\n",
      "torch.Size([4, 1, 77, 256, 256]) torch.Size([4, 77, 256, 256])\n",
      "\tmean 2.668e+05, max_z_sum 240 torch.Size([4, 4, 77, 256, 256])\n",
      "BS & loss 4 1369789.625\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.835e+05, max_z_sum 266 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1398531.75\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.763e+05, max_z_sum 275 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1317974.5\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.951e+05, max_z_sum 263 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1472249.125\n",
      "torch.Size([4, 1, 73, 256, 256]) torch.Size([4, 73, 256, 256])\n",
      "\tmean 2.390e+05, max_z_sum 243 torch.Size([4, 4, 73, 256, 256])\n",
      "BS & loss 4 1148984.875\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.137e+05, max_z_sum 298 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 941032.25\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.487e+05, max_z_sum 252 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1295078.375\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 2.780e+05, max_z_sum 275 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 1326410.625\n",
      "torch.Size([4, 1, 77, 256, 256]) torch.Size([4, 77, 256, 256])\n",
      "\tmean 2.653e+05, max_z_sum 279 torch.Size([4, 4, 77, 256, 256])\n",
      "BS & loss 4 1171392.125\n",
      "torch.Size([4, 1, 82, 256, 256]) torch.Size([4, 82, 256, 256])\n",
      "\tmean 1.228e+05, max_z_sum 301 torch.Size([4, 4, 82, 256, 256])\n",
      "BS & loss 4 535343.1875\n",
      "torch.Size([1, 1, 73, 256, 256]) torch.Size([1, 73, 256, 256])\n",
      "\tmean 3.328e+04, max_z_sum 73 torch.Size([1, 1, 73, 256, 256])\n",
      "BS & loss 4 33281.44140625\n",
      "Validation loss 1101328.6250 over 81 frames\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t = []\n",
    "val_loader1 = tavr_dataloader(validation, batch_size=4, shuffle=True, num_workers=2)\n",
    "val_loader2 = tavr_dataloader(validation, batch_size=16, shuffle=True, num_workers=2)\n",
    "val_loader3 = tavr_dataloader(validation, batch_size=4, shuffle=True, num_workers=5)\n",
    "val_loader4 = tavr_dataloader(validation, batch_size=16, shuffle=True, num_workers=5)\n",
    "\n",
    "t.append(time())\n",
    "test(model, val_loader1, loss_fn, device)\n",
    "t.append(time())\n",
    "test(ave_model, val_loader1, loss_fn, device)\n",
    "t.append(time())\n",
    "test(model, val_loader2, loss_fn, device)\n",
    "t.append(time())\n",
    "test(ave_model, val_loader2, loss_fn, device)\n",
    "t.append(time())\n",
    "test(model, val_loader3, loss_fn, device)\n",
    "t.append(time())\n",
    "test(ave_model, val_loader3, loss_fn, device)\n",
    "t.append(time())\n",
    "test(model, val_loader4, loss_fn, device)\n",
    "t.append(time())\n",
    "test(ave_model, val_loader4, loss_fn, device)\n",
    "t.append(time())\n",
    "\n",
    "for i in range(1, len(t)):\n",
    "    print(t[i]-t[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-10\n",
    "momentum = 0.90\n",
    "reg = 1e-7\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=reg, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****Epoch 0 Iteration 0, loss = 2208868.0000\n",
      "Validation loss 3691044.7500 over 81 frames\n",
      "conv_a1.weight,   \tnorm: 4.1727e+00, \tupdate norm: 2.1939e-03 \tUpdate/norm: 5.2577e-04\n",
      "conv_a1.bias,   \tnorm: 2.9972e-01, \tupdate norm: 5.0899e-07 \tUpdate/norm: 1.6982e-06\n",
      "conv_b1.weight,   \tnorm: 3.9208e+00, \tupdate norm: 2.8334e-03 \tUpdate/norm: 7.2265e-04\n",
      "conv_b1.bias,   \tnorm: 2.7325e-01, \tupdate norm: 7.9115e-07 \tUpdate/norm: 2.8953e-06\n",
      "final.weight,   \tnorm: 1.4334e+00, \tupdate norm: 1.8729e-03 \tUpdate/norm: 1.3066e-03\n",
      "final.bias,   \tnorm: 7.2517e-02, \tupdate norm: 8.8662e-07 \tUpdate/norm: 1.2226e-05\n",
      "\n",
      "Iter 0... ... ... \n",
      "Iteration 10, loss = 1262448.0000\n",
      "Validation loss 1824393.7500 over 81 frames\n",
      "conv_a1.weight,   \tnorm: 4.1699e+00, \tupdate norm: 4.0360e-03 \tUpdate/norm: 9.6790e-04\n",
      "conv_a1.bias,   \tnorm: 2.9973e-01, \tupdate norm: 1.0821e-06 \tUpdate/norm: 3.6104e-06\n",
      "conv_b1.weight,   \tnorm: 3.9255e+00, \tupdate norm: 5.2436e-03 \tUpdate/norm: 1.3358e-03\n",
      "conv_b1.bias,   \tnorm: 2.7326e-01, \tupdate norm: 1.7364e-06 \tUpdate/norm: 6.3544e-06\n",
      "final.weight,   \tnorm: 1.4370e+00, \tupdate norm: 3.4856e-03 \tUpdate/norm: 2.4255e-03\n",
      "final.bias,   \tnorm: 7.2535e-02, \tupdate norm: 1.9222e-06 \tUpdate/norm: 2.6501e-05\n",
      "\n",
      "Iter 10."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-44:\n",
      "Process Process-43:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fdb47db1b00>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 347, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 19153) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-ec873cdfcc2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train(model, optimizer, train_loader, val_loader, loss_fn, device, \n\u001b[0;32m----> 2\u001b[0;31m          epochs=1, print_every=10, print_level=3, lr_decay=0.8)\n\u001b[0m",
      "\u001b[0;32m~/Project/utils/run_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, val_loader, loss_fn, device, epochs, print_every, print_level, save_every, lr_decay)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mmax_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Project/Models/basic_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mb0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_a1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_b1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, optimizer, train_loader, val_loader, loss_fn, device, \n",
    "         epochs=1, print_every=10, print_level=3, lr_decay=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One last test + visualize results on 1 validation sequence\n",
    "val_seq = TAVR_Sequence(\"__valid\")\n",
    "test(model, val_loader, loss_fn, device)\n",
    "test(ave_model, val_loader, loss_fn, device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    ave_frames = [val_seq[0][0]]\n",
    "    for i in range(2,9,2):\n",
    "        ave_frame = model((val_seq[0][i-2][None,:], val_seq[0][i][None,:]))\n",
    "        ave_frames += [ave_frame[0][0],  val_seq[0][i]]\n",
    "    ave_frames += [val_seq[0][9]]\n",
    "    ave_frames_slices = []\n",
    "    for f in ave_frames:\n",
    "        ave_frames_slices += get_central_slices(f)\n",
    "    set_figsize(6,20)\n",
    "    display_grid(10, 3, ave_frames_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss 4033946.0000 over 81 frames\n",
      "Validation loss 1468.3656 over 81 frames\n",
      "Validation loss 0.2381 over 81 frames\n",
      "Validation loss 0.0047 over 81 frames\n",
      "105.04296255111694\n",
      "14.075073480606079\n",
      "107.34071278572083\n",
      "13.867462873458862\n"
     ]
    }
   ],
   "source": [
    "from utils.loss_functions import batch_mse_loss\n",
    "mse_loss_fn = batch_mse_loss()\n",
    "\n",
    "from time import time\n",
    "t = []\n",
    "t.append(time())\n",
    "test(model, val_loader, mse_loss_fn, device)\n",
    "t.append(time())\n",
    "test(ave_model, val_loader, mse_loss_fn, device)\n",
    "t.append(time())\n",
    "test(model, val_loader, loss_fn, device)\n",
    "t.append(time())\n",
    "test(ave_model, val_loader, loss_fn, device)\n",
    "t.append(time())\n",
    "\n",
    "for i in range(1, len(t)):\n",
    "    print(t[i]-t[i-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
