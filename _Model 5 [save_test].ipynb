{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training directory found, 36 series\n",
      "Validation directory found, 6 series\n",
      "Testing directory found, 10 series\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import utils.tavr_torch as tavr_torch\n",
    "from utils.tavr_torch import TAVR_3_Frame, TAVR_1_Frame, TAVR_Sequence, tavr_dataloader\n",
    "from utils.visualization import display_grid, z_stretch, visualize_frame, set_figsize, get_central_slices\n",
    "from utils.loss_functions import batch_l2_loss\n",
    "from utils.run_model import train, test, save, load, get_loss_history\n",
    "from Models.basic_models import average_model, two_layer_basic, post_process\n",
    "\n",
    "set_figsize(20, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('using device:', device)\n",
    "\n",
    "# \"Pixl\", \"Slice\", or \"None\"\n",
    "preproc_type = \"pixel\"\n",
    "\n",
    "validation = TAVR_3_Frame(\"__valid\", preproc=preproc_type)\n",
    "val_loader = tavr_dataloader(validation, batch_size=4, shuffle=True, num_workers=2)\n",
    "training = TAVR_3_Frame(\"__train\", preproc=preproc_type)\n",
    "train_loader = tavr_dataloader(training,batch_size=8, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "ave_model = average_model()\n",
    "model = two_layer_basic()\n",
    "post_proc = post_process(kind=preproc_type).to(device=device)\n",
    "loss_fn = batch_l2_loss()\n",
    "\n",
    "# CHANGE TO NAME OF JUPYTER NOTEBOOK\n",
    "model_name = \"Model 5 (Basic+PixelNorm)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-3\n",
    "momentum = 0.95\n",
    "reg = 1e-7\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=reg, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded from model_checkpoints/Model 5 (Basic+PixelNorm)/Model 5 (Basic+PixelNorm)-81\n"
     ]
    }
   ],
   "source": [
    "LOAD = True\n",
    "iteration_num = 81\n",
    "\n",
    "if LOAD:\n",
    "    load(model_name, iteration_num, model, optimizer)\n",
    "    loss_history = get_loss_history(model_name)\n",
    "    model.to(device=device)\n",
    "else:\n",
    "    loss_history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If multiple GPU\n",
    "# DO NOT CALL IF ONLY 1 GPU\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss 69.7419 over 81 frames\n"
     ]
    }
   ],
   "source": [
    "v_loss = test(model, post_proc, val_loader, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 0,\n",
       " 'iteration': 81,\n",
       " 'print_every': 30,\n",
       " 'train': [1.4583444595336914,\n",
       "  1.386093258857727,\n",
       "  1.303180456161499,\n",
       "  1.1800551414489746,\n",
       "  0.9898819923400879,\n",
       "  0.8864600658416748,\n",
       "  0.643781304359436,\n",
       "  0.41178756952285767,\n",
       "  0.2897035777568817,\n",
       "  0.32744431495666504,\n",
       "  0.41706836223602295,\n",
       "  0.4686945974826813,\n",
       "  0.5407416224479675,\n",
       "  0.6122727394104004,\n",
       "  0.5340273976325989,\n",
       "  0.5399351119995117,\n",
       "  0.4800082743167877,\n",
       "  0.41271457076072693,\n",
       "  0.3245951235294342,\n",
       "  0.2616511285305023,\n",
       "  0.24818198382854462,\n",
       "  0.26347947120666504,\n",
       "  0.2647935152053833,\n",
       "  0.2880227267742157,\n",
       "  0.29751893877983093,\n",
       "  0.29350441694259644,\n",
       "  0.3103369474411011,\n",
       "  0.29251813888549805,\n",
       "  0.2621140480041504,\n",
       "  0.23710985481739044,\n",
       "  0.23486699163913727,\n",
       "  0.21325638890266418,\n",
       "  0.19239456951618195,\n",
       "  0.20148739218711853,\n",
       "  0.2010451704263687,\n",
       "  0.19279226660728455,\n",
       "  0.20746038854122162,\n",
       "  0.21256385743618011,\n",
       "  0.2055629938840866,\n",
       "  0.20884472131729126,\n",
       "  0.19681207835674286,\n",
       "  0.1944475919008255,\n",
       "  0.18517182767391205,\n",
       "  0.19271022081375122,\n",
       "  0.18379157781600952,\n",
       "  0.18671277165412903,\n",
       "  0.20430240035057068,\n",
       "  0.18582960963249207,\n",
       "  0.17607268691062927,\n",
       "  0.18648572266101837,\n",
       "  0.17755115032196045,\n",
       "  0.17921467125415802,\n",
       "  0.18191157281398773,\n",
       "  0.16941122710704803,\n",
       "  0.18211999535560608,\n",
       "  0.18449018895626068,\n",
       "  0.18318866193294525,\n",
       "  0.1736374944448471,\n",
       "  0.1736517995595932,\n",
       "  0.18381933867931366,\n",
       "  0.16353361308574677,\n",
       "  0.17456315457820892,\n",
       "  0.17431114614009857,\n",
       "  0.16672681272029877,\n",
       "  0.15789996087551117,\n",
       "  0.17174756526947021,\n",
       "  0.1557217240333557,\n",
       "  0.1695527881383896,\n",
       "  0.151475727558136,\n",
       "  0.15625005960464478,\n",
       "  0.15287239849567413,\n",
       "  0.17425255477428436,\n",
       "  0.16761142015457153,\n",
       "  0.1567942202091217,\n",
       "  0.14946486055850983,\n",
       "  0.14780698716640472,\n",
       "  0.1605977863073349,\n",
       "  0.14583201706409454,\n",
       "  0.15747636556625366,\n",
       "  0.1633317917585373,\n",
       "  0.15516407787799835],\n",
       " 'train_c': [678.6041259765625, 109.28948974609375, 76.09627532958984],\n",
       " 'valid': [659.8191528320312, 95.93801879882812, 76.11701965332031]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
